# NuvaFace - AI-Powered Aesthetic Simulation

NuvaFace is a proof-of-concept system for simulating aesthetic procedures using advanced AI diffusion models. It provides realistic previews of filler and Botox treatments through state-of-the-art image generation techniques.

## ‚ö†Ô∏è Important Disclaimer

**This is a visualization tool for educational purposes only.** Results are AI-generated simulations and do not guarantee actual treatment outcomes. Always consult with qualified medical professionals for real aesthetic procedures.

## üéØ Features

### Supported Procedures
- **Filler Simulation**: Lips, Chin, Cheeks
- **Botox Simulation**: Forehead wrinkles

### Technical Capabilities
- MediaPipe-based facial landmark detection
- Stable Diffusion inpainting with ControlNet guidance
- InstructPix2Pix alternative pipeline
- Real-time mask editing
- Quality control with identity preservation metrics
- Responsive web interface

## üèóÔ∏è Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Web UI        ‚îÇ    ‚îÇ   FastAPI       ‚îÇ    ‚îÇ   ML Engine     ‚îÇ
‚îÇ                 ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ                 ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ                 ‚îÇ
‚îÇ ‚Ä¢ Upload        ‚îÇ    ‚îÇ ‚Ä¢ /segment      ‚îÇ    ‚îÇ ‚Ä¢ Face parsing  ‚îÇ
‚îÇ ‚Ä¢ Area select   ‚îÇ    ‚îÇ ‚Ä¢ /simulate/*   ‚îÇ    ‚îÇ ‚Ä¢ ControlNet    ‚îÇ
‚îÇ ‚Ä¢ Mask editor   ‚îÇ    ‚îÇ ‚Ä¢ Quality check ‚îÇ    ‚îÇ ‚Ä¢ SD Inpainting ‚îÇ
‚îÇ ‚Ä¢ Results view  ‚îÇ    ‚îÇ                 ‚îÇ    ‚îÇ ‚Ä¢ Quality ctrl  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Pipeline Overview (Weg A)

1. **Upload** ‚Üí Face alignment & preprocessing (768px)
2. **Segmentation** ‚Üí MediaPipe FaceMesh ‚Üí Area masks
3. **Control Maps** ‚Üí Canny + Depth (SD) / SoftEdge + Depth (IP2P)
4. **Diffusion** ‚Üí SD-Inpainting + dual ControlNet
5. **Quality Control** ‚Üí ArcFace ID + SSIM off-mask
6. **Results** ‚Üí Blended output with metrics

## üöÄ Quick Start

### Installation

1. **Prerequisites**
   ```bash
   # Ensure you have conda/miniconda installed
   conda --version
   ```

2. **Run Installation Script**
   ```bash
   chmod +x install.sh
   ./install.sh
   ```

3. **Activate Environment**
   ```bash
   conda activate nuvaface
   ```

### Starting the Server

```bash
# Development server
uvicorn api.main:app --host 0.0.0.0 --port 8000 --reload
```

### Using the Web Interface

1. Open `http://localhost:8000/docs` for API documentation
2. Open `ui/index.html` in your browser for the web interface
3. Upload a frontal face photo
4. Select treatment area (lips, chin, cheeks, forehead)
5. Adjust effect strength (0-100%)
6. Generate simulation

## üìã API Reference

### Health Check
```bash
GET /health
```

### Face Segmentation
```bash
POST /segment
{
  "image": "base64_string",
  "area": "lips|chin|cheeks|forehead",
  "feather_px": 3
}
```

### Filler Simulation
```bash
POST /simulate/filler
{
  "image": "base64_string",
  "area": "lips|chin|cheeks",
  "strength": 50,
  "pipeline": "sd_inpaint|ip2p",
  "seed": 12345
}
```

### Botox Simulation
```bash
POST /simulate/botox
{
  "image": "base64_string", 
  "area": "forehead",
  "strength": 50,
  "pipeline": "sd_inpaint",
  "seed": 12345
}
```

### Example Usage
```bash
curl -X POST http://localhost:8000/simulate/filler \
  -H "Content-Type: application/json" \
  -d '{
    "image": "iVBORw0KGgoAAAANSUhEUgAA...",
    "area": "lips",
    "strength": 60,
    "pipeline": "sd_inpaint",
    "seed": 123
  }'
```

## ‚öôÔ∏è Configuration

### Model Settings
The system uses these pre-trained models:
- **SD Inpainting**: `runwayml/stable-diffusion-inpainting`
- **InstructPix2Pix**: `timbrooks/instruct-pix2pix`
- **ControlNet**: `lllyasviel/sd-controlnet-*`
- **Face Analysis**: MediaPipe FaceMesh + InsightFace ArcFace

### Performance Tuning
```python
# Recommended settings for RTX 3090
steps = 30
resolution = 768
fp16 = True
xformers = True
```

### Quality Thresholds
```python
id_similarity_threshold = 0.35  # ArcFace warning
ssim_threshold = 0.98          # Off-target protection
```

## üß™ Testing

### Run Quality Control Tests
```bash
python -m pytest tests/test_qc.py -v
```

### Manual Testing Workflow
1. Upload test images from `tests/data/`
2. Test each area type
3. Verify quality metrics
4. Check edge cases (no face, multiple faces)

## üìä Quality Metrics

### Identity Preservation
- **Method**: ArcFace cosine similarity
- **Threshold**: > 0.65 (good), < 0.35 (warning)
- **Purpose**: Ensure person remains recognizable

### Off-Target Protection  
- **Method**: SSIM in non-masked regions
- **Threshold**: > 0.98
- **Purpose**: Prevent unwanted changes outside treatment area

### Image Quality
- **Method**: BRISQUE score comparison
- **Threshold**: < 10 point increase
- **Purpose**: Maintain perceptual quality

## üî¨ Scientific Background

### Botox Pipeline Research
The forehead treatment implements a two-stage pipeline based on ACCV 2022 research:

1. **Segmentation Stage**: Precise wrinkle area identification
2. **Inpainting Stage**: Texture-aware filling with global context

This approach achieves state-of-the-art results for photorealistic wrinkle removal while preserving natural skin texture.

**Future Enhancement**: Integration of Unet++ segmentation and LaMa/FFC inpainting models for improved clinical accuracy.

## üìÅ Project Structure

```
NuvaFace_MVPneu/
‚îú‚îÄ‚îÄ api/                    # FastAPI application
‚îÇ   ‚îú‚îÄ‚îÄ main.py            # API routes and handlers
‚îÇ   ‚îî‚îÄ‚îÄ schemas.py         # Pydantic models
‚îú‚îÄ‚îÄ engine/                # ML processing pipeline
‚îÇ   ‚îú‚îÄ‚îÄ utils.py           # I/O, preprocessing
‚îÇ   ‚îú‚îÄ‚îÄ parsing.py         # Face segmentation
‚îÇ   ‚îú‚îÄ‚îÄ controls.py        # ControlNet preprocessing  
‚îÇ   ‚îú‚îÄ‚îÄ edit_sd.py         # SD inpainting pipeline
‚îÇ   ‚îú‚îÄ‚îÄ edit_ip2p.py       # InstructPix2Pix pipeline
‚îÇ   ‚îî‚îÄ‚îÄ qc.py              # Quality control
‚îú‚îÄ‚îÄ models/                # Model loading and caching
‚îú‚îÄ‚îÄ ui/                    # Web interface
‚îÇ   ‚îú‚îÄ‚îÄ index.html         # Main UI
‚îÇ   ‚îú‚îÄ‚îÄ app.js             # JavaScript logic
‚îÇ   ‚îî‚îÄ‚îÄ styles.css         # Styling
‚îú‚îÄ‚îÄ docs/                  # Documentation
‚îÇ   ‚îú‚îÄ‚îÄ PROMPTS.md         # Prompt templates
‚îÇ   ‚îî‚îÄ‚îÄ ASSUMPTIONS.md     # Technical assumptions
‚îú‚îÄ‚îÄ tests/                 # Test suite
‚îî‚îÄ‚îÄ install.sh             # Installation script
```

## üõ£Ô∏è Roadmap

### Weg A (Current) - Diffusion Editing
- ‚úÖ SD Inpainting + ControlNet
- ‚úÖ InstructPix2Pix alternative
- ‚úÖ Quality control system
- ‚úÖ Web interface

### Weg B (Future) - Hybrid Approach
- üîÑ Geometric warping (TPS) for shape control
- üîÑ Combined geometry + texture editing
- üîÑ Improved form determinism for lips
- üîÑ API-compatible integration

### Clinical Enhancements
- üîÑ Unet++ segmentation model
- üîÑ LaMa/FFC inpainting integration
- üîÑ Wrinkle-specific loss functions
- üîÑ Clinical validation studies

## ü§ù Contributing

1. **Development Setup**
   ```bash
   git clone <repository>
   cd NuvaFace_MVPneu
   ./install.sh
   conda activate nuvaface
   ```

2. **Code Style**
   - Follow PEP 8 for Python
   - Use TypeScript-style JSDoc for JavaScript
   - Test changes with quality control suite

3. **Testing**
   - Add tests for new features
   - Verify quality metrics on test dataset
   - Document assumptions in `ASSUMPTIONS.md`

## üìù License

This project is for research and educational purposes. Commercial use requires appropriate licensing of the underlying models:

- Stable Diffusion: CreativeML Open RAIL-M
- MediaPipe: Apache 2.0
- InsightFace: Academic use license

## üÜò Troubleshooting

### Common Issues

**GPU Out of Memory**
```bash
# Reduce batch size or enable CPU offloading
export CUDA_VISIBLE_DEVICES=""  # Force CPU mode
```

**Model Download Errors**
```bash
# Clear cache and retry
rm -rf ~/.cache/huggingface/
python -c "from models import get_sd_inpaint_pipeline; get_sd_inpaint_pipeline()"
```

**API Connection Issues**
```bash
# Check server status
curl http://localhost:8000/health

# Verify CORS settings in production
```

### Performance Optimization

**Faster Inference**
- Use fp16 precision
- Enable xformers attention
- Reduce inference steps (20-25)
- Cache models in memory

**Memory Management**
- Enable model CPU offloading
- Use gradient checkpointing
- Reduce image resolution

## üìû Support

- **Documentation**: See `docs/` directory
- **API Reference**: `http://localhost:8000/docs`
- **Issues**: Check troubleshooting section
- **Research**: See scientific references in documentation

---

**Version**: 1.0.0  
**Last Updated**: 2024  
**Status**: Proof of Concept (Weg A Complete)  

*This README provides a comprehensive overview of the NuvaFace system. For detailed technical information, refer to the documentation in the `docs/` directory.*